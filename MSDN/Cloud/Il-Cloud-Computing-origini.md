---
title: Il Cloud Computing - origini
description: Il Cloud Computing - origini
author: MSCommunityPubService
ms.date: 08/01/2016
ms.topic: how-to-article
ms.service: cloud
ms.custom: CommunityDocs
---

# Il Cloud Computing - origini

#### Di [Roberto Freato](https://mvp.support.microsoft.com/profile/Roberto) – Microsoft MVP

![](./img/Il-Cloud-Computing-origini/image1.png)

*Settembre 2012*

In questo articolo verranno discussi i seguenti argomenti:

- Storia del Cloud Computing

## Sommario
--------

- Introduzione
- La nascita del Cloud Computing
- X-Computing: le ere che porteranno al Cloud
- Il CERN: la più grande Grid europea
- Il Grid e le Information Utilities
- La virtualizzazione
- Cloud Computing


In questo articolo parleremo, per la prima volta in questo contesto, di
storia del Cloud Computing, enfatizzando le cause che ne hanno generato
la nascita e la crescita e puntando l’attenzione sui concetti base che
dovrebbero contraddistinguere ogni prodotto commerciale che porti
“cloud” nel proprio nome.

## Introduzione

Assistiamo oggi ad un continuo processo d’innovazione e sviluppo che
coinvolge tutti i campi dell’umana conoscenza provocando molto spesso
disorientamento per coloro che in tali campi non lavorano, ma sono
stupefatti da tali progressi al punto che a volte, una data
scoperta/evoluzione provoca inconsapevolmente su tutti gli individui un
condizionamento tale da modificare i nostri usi e costumi quotidiani.

Evitando troppe generalizzazioni e restringendo il nostro campo
d’interesse alle innovazioni tecnologiche, è evidente che nell’ultimo
decennio, il processo di evoluzione dell’informatica e della
microelettronica abbia alterato completamente le nostre abitudini, il
nostro modo di lavorare e di interagire con gli altri. Quello che oggi
reputiamo necessario, ad esempio computer e cellulari, un tempo era
veramente un’esigenza che pochi potevano permettersi economicamente e
ancor più che pochi sapevano utilizzare. Abbiamo potuto osservare in
pochi anni come l’utilizzo della tecnologia, riservata prevalentemente
al mondo accademico per la ricerca e al mondo business a supporto delle
attività lavorative, si sia integrata completamente negli usi comuni di
qualsiasi categoria di utenza. Ogni giorno assistiamo a qualche
cambiamento che alla fine avrà impatto sulla vita quotidiana di ciascuno
di noi.

È proprio da tali premesse che un tema come il Cloud Computing, che
all’inizio della sua nascita sembrava potesse essere comprensibile e
utilizzabile da pochi, è ad oggi una delle tematiche più affrontate sul
web. Noi cercheremo di chiarire la moltitudine di dubbi che ancora oggi
suscita il Cloud, dubbi che probabilmente nascono dai non addetti al
settore che pur non avendo piena coscienza di cosa sia, vogliono
assolutamente esserne partecipi. Ripercorrendo la storia di questi
ultimi vent’anni, cercheremo di comprendere affondo il reale significato
del Cloud Computing e i cambiamenti che ad esso sono conseguiti.

## La nascita del Cloud Computing

Come nasce il Cloud Computing? Per giungere ad una chiara definizione
bisogna ritornare indietro nel tempo, in quanto il Cloud è la
convergenza di una serie di tecnologie che si sono sviluppate negli
ultimi trent’anni. I suoi predecessori sono il risultato della stretta
interconnessione tra tecnologia informatica e ricerca scientifica. Da
sempre, infatti, la ricerca scientifica è svolta da comunità di
ricercatori geograficamente distribuiti sul territorio mondiale e
caratterizzati da un’eterogeneità di risorse quali: sistemi di calcolo,
strumenti scientifici, banche dati, sensori, componenti software, reti,
tali che i migliori risultati scientifici siano la conseguenza delle
molteplici collaborazioni su scala globale in cui l'informazione e la
tecnologia informatica svolgono un ruolo fondamentale, motivo per il
quale tale legame abbia dato vita al concetto di *e-Science*.

    **Nota: **
    Il termine *e-Science* caratterizza quella ricerca scientifica che
    utilizza una grande quantità di risorse di calcolo e grandi quantità
    di dati geograficamente distribuiti. Ci si riferisce alla ricerca
    scientifica su scala mondiale condotta attraverso collaborazioni
    distribuite e supportate dall’utilizzo di Internet

Da qui il Grid Computing. Esso è emerso come uno dei principali
paradigmi di calcolo che consentono la creazione e la gestione di
infrastrutture basate su Internet per la realizzazione di *e-Science* ed
*e-business* a livello globale. Numerosi progetti nazionali e
internazionali in tutto il mondo sono stati avviati a svolgere attività
di ricerca e innovazione che trasformano la visione di *e-Science* e
Grid Computing in realtà.

Siamo nell’era dell’*e-Science*, l’era della scienza elettronica, dove
la maggior parte degli esperimenti non si basa più su microscopi,
provette o test su cavie di laboratorio ma vengono quasi tutti fatti al
computer perché la crescente capacità di calcolo dei computer e la
sempre maggiore diffusione di Internet hanno consentito agli scienziati
di tutte le discipline di creare dei veri laboratori virtuali, dove
eseguire esperimenti non più “in vivo”, ma “in silicio” .

I campi di applicazione dell’informatica alla scienza sono innumerevoli.
Il problema principale, nonché sfida tecnologica, nasce nel riuscire a
far convergere i dati provenienti da diversi campi scientifici su un
unico computer, in particolar modo in quelle discipline che sono al
confine tra due settori. Il dialogo tra le varie discipline deve essere
assicurato dalle scienze computazionali che hanno la capacità,
attraverso software dedicati, di far parlare la medicina e la biologia,
la chimica e l’astronomia, la fisica e l’ingegneria. Questo spiega
perché i centri di ricerca scientifica più importanti del mondo abbiano
affiancato alla determinazione di conseguire i propri obiettivi, la
necessità di migliorare i propri sistemi informatici, troppo poco
adeguati a causa del ridotto budget disponibile.

Una risposta a questi problemi è rappresentata proprio dal Grid
Computing:

*«un sistema che permette l’aumento delle capacità computazionali grazie
alla creazione di una rete “organica” di risorse hardware, situate in
luoghi diversi, e quindi appartenenti ad organizzazioni di ricerca
diverse»*.

## X-Computing: le ere che porteranno al Cloud

    **Nota:**
    Per X si intendono tutte le varianti, le forme e le diciture di
    Distributed Computing che si sono manifestate negli ultimi anni

Nel tentativo di ripercorrere sinteticamente il fenomeno della
condivisione delle risorse di calcolo, si possono distinguere quattro
ere.

Nella prima era (anni ’70) erano ancora in pochi ad avere la possibilità
di utilizzare le risorse di calcolo a causa dei costi ancora troppo
alti, infatti erano solamente le grandi aziende a potersi permettere un
investimento simile. Per tale motivo, questa fase fu rinominata l’era
del “computer per molti utenti”.

Negli anni ’80, la riduzione dei costi hardware ha cambiato radicalmente
lo scenario, consentendo a moltissimi di poter avere un computer
personale per ragioni non strettamente tecniche. È da questa era che i
primi centri di ricerca si focalizzarono sull’importanza di tale potenza
di calcolo a supporto delle loro attività: siamo nell’era in cui il
computer era principalmente uno strumento di calcolo scientifico e
teorico.

Negli anni ’90 la situazione si sviluppa a tal punto da parlare di
“molti computer per un singolo utente”. L’utente, incuriosito dalla
possibilità di poter possedere a un prezzo basso uno strumento
tecnologico tanto potente, ha cominciato ad utilizzare il computer per
svariate funzioni: come archivio dei propri dati, come strumento di
svago fino a divenire, con l’avvento di Internet, uno strumento di
interazione e comunicazione sociale. La crescita della memoria di massa
e della larghezza di banda disponibile, ha permesso infatti la
condivisione delle risorse computazionali non adiacenti che ha portato
alla nascita del modello distribuito di computing che è quanto abbiamo
oggi. Si è assistito in pochi anni alla nascita delle architetture
cluster, cioè di un aggregato di nodi computazionali interconnessi tra
di loro attraverso la rete e con protocolli standard. La diffusione di
protocolli TCP/IP di Internet ha reso possibile poi lo sviluppo di
architetture completamente distribuite che hanno dato il via al Grid
Computing, il cui processo di maturazione converge nella creazione di
una struttura affidabile e completamente scalabile . Il web ha abbattuto
in tal senso le barriere legate alle distanze territoriali tra le
persone e le cose, consentendo a tutti gli utenti di rimanere ancora più
affascinati dall’utilizzo del computer, al punto che oggi non è
possibile escludere nessuno quando si parla di evoluzione informatica.

### Il CERN: la più grande Grid europea

La più grande Grid europea è quella del CERN di Ginevra. Infatti, la
necessità di condividere enormi risorse di calcolo distribuite
territorialmente è conseguenza del processo di trasformazione del grande
acceleratore di particelle europeo del CERN che ha dato il via ad un
progetto conosciuto per l’appunto sotto il nome di Data Grid.

    **Nota: **
    Il CERN (Organizzazione Europea di Ricerche Nucleari) è il più
    grande laboratorio al mondo di fisica delle particelle. Si trova al
    confine tra la Svizzera e la Francia, alla periferia ovest della
    città di Ginevra. Esso fornisce ai ricercatori gli strumenti
    necessari per la ricerca in fisica delle alte energie attraverso
    complessi esperimenti. Questi strumenti sono principalmente gli
    acceleratori di particelle.

La Grid, che è stata realizzata per supportare tale attività, è basata
su fibra ottica e collega il CERN a undici centri situati in Europa,
Canada e Asia con l’obiettivo di registrare i dati del *Large Hadron
Collider* (LHC): l'acceleratore di particelle progettato per analizzare
come è nato l'universo. La nuova tecnologia collegava più di 50.000
server, che sarebbero diventati 300.000 dopo poco tempo. Già allora ci
si era resi conto delle potenzialità di un sistema di tale portata: esso
avrebbe consentito a chiunque di poter accedere ai propri dati da
qualsiasi posto del mondo e in tempi stupefacenti. Ed è da tale progetto
che la comunità europea decise di investire altro denaro in tale
architettura informatica, al fine di stabilizzarne l’infrastruttura,
convergendo nel progetto [Enabling Grid for E-science in
Europe](http://www.eu-egee.org/).

    **Nota:**
    L’avvio dell’attività operativa dell’Large Computing Grid applicata
    all’Lhc è stata celebrata con un evento, il Grid Fest, nel corso del
    quale sono stati premiati i partner tecnologici strategici del
    progetto: Hp, Intel e Oracle. Quest’ultima ha collaborato al
    progetto 3D (Distributed Deployment of Databases) per la
    distribuzione ai massimi livelli di scalabilità e affidabilità delle
    informazioni necessarie all’elaborazione e analisi dei dati generati
    dagli eventi dell’Lhc, mentre ad Intel e Hp si deve la “griglia”
    vera e propria. Questa è formata da circa 100 mila Cpu Intel. Il
    risultato di una riduzione di circa 2,5MW, impossibile con normali
    architetture, è stato raggiunto grazie a una collaborazione per
    l’ottimizzazione del software utilizzato dal Cern in funzione
    dell’introduzione progressiva delle ultime tecnologie multicore. Le
    Cpu del Grid sono interconnesse grazie alle soluzioni e alla
    tecnologia ‘adaptive networking’ di Hp Procurve. La rete ha una
    topologia gerarchica, con un nucleo presso il Cern e centri di primo
    e di secondo livello dislocati in vari Paesi. Oltre 2000 switch Hp
    Procurve serie 3400 e 3500 controllano la griglia del campus Cern e
    sono a loro volta controllati da 10 ‘core switch’ serie 8212 che
    centralizzano gestione e sicurezza dell’intera infrastruttura. La
    griglia abilita un’attività che nel 2008 ha superato i 100 mila
    ‘job’ al giorno

## Il Grid e le Information Utilities

Il concetto cui stiamo giungendo si fa sempre più interessante poiché
alla fine degli anni ’90, non si cercava soltanto di condividere le
risorse distribuite cercando di standardizzarne l’accesso, ma si stava
giungendo ad un concetto molto più complesso e affascinante che è quello
di *utility computing* che appaga le necessità non solo dei ricercatori
ma anche del mondo business e consumer che farà dell’*utility computing*
una nuova prospettiva di fruizione dei servizi IT.

Cosa si nasconde dietro tale concetto? Si riporta di seguito una
definizione di Foster e Kasselman sul Grid Computing:

*«una infrastruttura hardware e software in grado di fornire un accesso
differenziale, consistente, pervasivo, ed economico a risorse
computazionali di fascia elevata».*

Sarà breve il passaggio dal Grid a quello di *Information Utilities*,
intendendo con esso la possibilità di fornire un insieme di servizi a
consumo al pari delle *public utilities*. Ormai la richiesta di risorse
computazionali è diventata importante quanto la necessità di
elettricità, telefonia, acqua e quindi tali risorse devono poter essere
fornite all’utente in funzione del loro utilizzo e delle loro necessità.
L’utente deve completamente disinteressarsi di dove il sistema vada a
recuperare le effettive risorse necessarie perché sarà esso stesso a
gestire la richiesta e a monitorarne il processo di esecuzione in
completa autonomia. Perché realizzare e aderire ad un modello simile? Ci
sono due ragioni: una tecnologica e una economica.

Dal punto di vista tecnologico, la diffusione del modello *utility*
garantisce che gli applicativi, nei quali si sono investite risorse,
siano rapidamente e facilmente trasferibili da un’infrastruttura ad
un’altra, che sia proprietaria o fornita da terze parti esterne
all’azienda. La standardizzazione dell’utilizzo delle risorse
elaborative, garantito dalle *Computational Grids*, consente di produrre
applicativi indipendenti dalla specifica tecnologia hardware/software
allo stesso modo in cui il protocollo Internet TCP/IP ha permesso la
standardizzazione delle risorse di interconnessione.

Dal punto di vista economico, si ha la trasformazione dei costi fissi in
costi variabili, con la promessa di una gestione contabile maggiormente
semplificata, in linea con quanto avviene per la fornitura dei servizi
essenziali. La standardizzazione dell’utilizzo delle risorse di calcolo
rende inoltre possibile il raggiungimento di un obiettivo da sempre
molto difficile per l’informatica: la saturazione delle risorse
disponibili. Comunità di aziende, istituzioni ed individui che lavorano
per conseguire degli obiettivi condivisi, potranno poi utilizzare le
*Computational Grids* per condividere le risorse, i dati e gli strumenti
con cui affrontare i problemi comuni. Gli utilizzatori saltuari, aziende
che magari utilizzano in maniera consistente le loro risorse elaborative
solo in determinati giorni del mese o della settimana, possono invece
trovare convenienza in contratti di servizio nei confronti di fornitori
esterni, ottenendo significative economie e nel contempo migliorando i
livelli di servizio cui erano abituati .

## La virtualizzazione

Prima di poter dare una definizione esaustiva di Cloud Computing è necessario però introdurre un altro concetto: la virtualizzazione. Molti considerano il Cloud Computing e la virtualizzazione come due temi
inscindibili (e questa è una delle motivazioni che ci consentono di distinguere il Cloud Computing dal Grid). È comunque alla virtualizzazione che si deve la visione dinamica delle applicazioni aziendali che ha portato poi ai concetti che trattiamo oggi.

Il concetto di virtualizzazione risale al 1967 con il mainframe e il partizionamento della macchina per avere, all’interno di un unico sistema, un numero ingente di applicazioni. Inoltre con la constatazione
che l’utilizzo effettivo dei server è tra il 15% e il 20% delle loro capacità, si è deciso di consolidare in un unico server un gran numero di server in modo da averne meno e sfruttarli al massimo. Paul Maritz,
il CEO di VMWare, azienda leader nel settore della virtualizzazione, afferma a tal proposito:

*«Il futuro della virtualizzazione è nel Cloud Computing. E, viceversa,
non ci potrà essere un vero decollo del Cloud Computing senza
virtualizzazione perché altrimenti le applicazioni già esistenti
andrebbero re ingegnerizzate, come accade oggi per molti fornitori di
Cloud. Il primo passo della nostra visione sarà la trasformazione del
data center aziendale in un servizio di Cloud Computing per realizzare
ciò che potremmo chiamare data center-as-a-service ».*

L’obiettivo che si vuole raggiungere è quello di riuscire a realizzare
una *Virtual private Cloud*. Consapevoli del sottosfruttamento dei
server, si vuole realizzare una trasformazione dagli attuali data center
a dei mainframe software attraverso la definizione di strati software
che compongono quello che ad oggi viene comunemente chiamato *virtual
data center* e che è stato battezzato da VMWare come vSphere. Esso è il
primo sistema operativo Cloud del settore; infatti, utilizza la
virtualizzazione per trasformare i data center in infrastrutture di
Cloud Computing che consentano alle organizzazioni IT di erogare servizi
di nuova generazione, più affidabili e flessibili.

## Cloud Computing

Detto questo, è possibile dare una visione chiara del concetto di Cloud,
visto che si sono analizzate le principali tecnologie pregresse che
fanno del Cloud ad oggi il paradigma predominante. In realtà, ancora
oggi, la distinzione chiara e precisa tra il Cloud Computing e i suoi
predecessori è molto fumosa; c’è addirittura chi utilizza Cloud e Grid
come sinonimi. Questo, in determinati contesti ed utilizzi, può essere
consentito ma i due paradigmi rimangono nella loro essenza da
distinguere. Come già detto in precedenza, negli anni ’90, il termine
Grid era utilizzato per indicare quelle tecnologie che avrebbero
permesso agli utenti di condividere una grande quantità di risorse il
cui potere computazionale poteva essere ottenuto *on demand*. Allo
stesso modo si può parlare del Cloud Computing: la visione è la medesima
e l’adesione a tale paradigma consente di ridurre i costi di
computazione, aumentare l’affidabilità e la flessibilità dei servizi e
soprattutto cambiare completamente lo scenario delle aziende consentendo
loro di porre in outsourcing buona parte di tali risorse.

Altro aspetto che consente di distinguere tali tecnologie è l’era in cui
siano nate e le diverse esigenze delle persone a cui siano rivolte. In
particolare, tra il Grid e il Cloud ci sono dieci anni di evoluzioni
scientifico/tecnologiche che dovrebbero far capire come queste due
tecnologie si differenzino inevitabilmente. Non solo: il Cloud nasce in
un contesto in cui la standardizzazione dei protocolli di rete ne
facilitano l’adesione e si vedrà come esso diventi materia attrattiva
non solo delle grandi aziende e del mondo accademico, ma anche del
piccolo programmatore. Senza che l’utente se ne renda conto, molte delle
applicazioni offerte oggi poggiano sul Cloud e molte aziende stanno
cercando di migrare verso il Cloud al fine di ridurre i propri costi.
L’idea è di far migrare i propri dati all’interno di server
geograficamente dispersi senza che ci si interroghi su dove
effettivamente risiedano, ma con la prerogativa che essi siano
accessibili e disponibili da qualsiasi postazione in cui si trovi
l’utente. La mancata necessità da parte dell’utente e delle aziende di
avere il possesso fisico e il controllo diretto delle proprie risorse
hardware e software è una caratteristica abilitante del Cloud Computing
e assisteremo nei prossimi anni alla parziale se non completa scomparsa
di quelle applicazioni e servizi che, per essere utilizzati, debbano
essere installati sulla singola macchina utente; tutto sarà disponibile
*on demand* da qualsiasi luogo e attraverso qualsiasi dispositivo
utilizzato.

Nel Marzo del 2009 è stato pubblicato, attraverso la collaborazione di
molteplici organizzazioni quali IBM, AMD, VMWare, Cisco, EMP, SAP, Sun,
Novell e altre ancora, l'[Open Cloud
Manifesto](http://www.opencloudmanifesto.org/). Esso si propone di
tracciare i principi di base del Cloud Computing risolvendo alcune delle
problematiche tecnologiche (ad esempio la sicurezza e
l'interoperabilità) legate a questo nuovo paradigma. Il Manifesto si
pone l’obiettivo di favorire l'uso di standard aperti per il Cloud
Computing in modo che nel tempo non nascano piattaforme proprietarie che
andrebbero a rallentarne lo sviluppo.

Purtroppo però le tematiche Cloud hanno sin da subito suscitato
confusione per coloro che ne sostengono il paradigma e per coloro che
vogliono aderirvi al punto da generare anche delle controversie nella
formulazione del Manifesto. Infatti, al momento della stesura del
documento mancavano alcune grandi aziende del mercato che stavano
investendo molto nel Cloud e che mostravano disappunto nei confronti
dell’Open Cloud Manifesto, come ad esempio Microsoft e Amazon.
Sembrerebbe che la notizia della stesura del documento fu resa nota da
un post sul blog corporate di Microsoft e che le sei pagine di cui è
composto siano state discusse a porte chiuse tra i firmatari iniziali.
Microsoft è apparsa perciò da subito perplessa sul processo che avrebbe
portato alla definizione del manifesto e alla sua distribuzione,
processo che è stato come detto portato a compimento a porte chiuse,
senza la possibilità di intervenire e proporre suggerimenti.
Probabilmente la causa di questi conflitti è legata anche ai troppi
vendor di Cloud Computing presenti sul mercato e alle molteplici
soluzioni proposte. La presenza di un numero cosi alto di vendor è
legata anche alla migrazione sul Cloud da parte di un sempre maggior
numero di aziende le quali vedono nel Cloud un effettivo vantaggio
economico.

Per le aziende, infatti, il vantaggio di aderire al Cloud è legato alla
possibilità di non investire sulle infrastrutture informatiche ma di
comprare completamente *on demand,* da un'azienda che offre servizi
Cloud Computing, potenza di calcolo, storage e servizi informatici.
[Gartner](http://www.gartner.com/technology/home.jsp), una delle
principali società di ricerca a livello mondiale, sottolinea come i
servizi offerti dal Cloud debbano poter essere scalati verso l'alto o
verso il basso a seconda delle esigenze dell'utente in termini di
capacità. Secondo la società di ricerca, il **Cloud Computing** avrà
moltissime adesioni, a livello mondiale i proventi legati al Cloud sono
stati **superiori a 56,3 miliardi di dollari** e cresceranno
progressivamente fino a raggiungere i 150 miliardi di dollari nel 2013.
Buona parte di tale contributo coinvolgerà inizialmente i seguenti
servizi: **pubblicità, e-commerce, gestione risorse umane e
transazioni**. Nel settore pubblicitario in particolare, i servizi
Google, ai quali si stanno adeguando anche Microsoft e Yahoo!, ricoprono
**il 60% di tutti i servizi Cloud** e domineranno la scena ancora per i
prossimi quattro anni. I tagli ai bilanci e la difficoltà di riuscire a
stimare le risorse hardware necessarie alle aziende nei prossimi anni
sono, secondo Gartner, la ragione principale che induce le aziende a
rivolgersi ai servizi remoti.

In uno scenario IT talmente complesso, l’idea è quella di porre in
outsourcing tutto quello che porta ad un risparmio economico. In tal
modo il Cloud Computing abilita questi servizi fornendo scalabilità ed
efficienza, garantendo Quality of Service personalizzato sulle esigenze
del cliente, consentendo l’accesso alle risorse *on demand* in modo che
tutto ciò che l’utente desideri sia accessibile e disponibile sempre e
in modo semplice.

Il Cloud Computing può essere analizzato a tre livelli:

1.  *SaaS (Software as a Service)*: consiste nell'utilizzo di programmi
    in remoto, spesso attraverso un server web. Questo acronimo è
    pressappoco un sinonimo, in Italia, del termine ASP (oggi
    in disuso). Il cliente di un provider SaaS è l'utente finale e il
    provider stesso può utilizzare uno IaaS o PaaS di terze parti per
    fornire potenza di calcolo, storage e infrastruttura di rete. Tipici
    servizi che sono già presenti sul mercato sono applicativi di base
    come CRM, ERP, backup dei dati centralizzati, documentali, mail
    e archiviazione.

2.  *PaaS (Platform as a Service)*: offre un ambiente di sviluppo per il
    codice dell'applicazione, servizi Cloud, potere elaborativo, lo
    stoccaggio e le infrastrutture di rete. Il pacchetto applicativo
    contiene solo ciò che è stato sviluppato dal proprietario del
    software utilizzando un ambiente di programmazione che è supportato
    dal fornitore PaaS. Ad esempio, Azure Services Platform di Microsoft
    supporta il framework .NET e PHP, oppure Google App Engine supporta
    Java e Python. Un'altra distinzione tra ambienti PaaS e ambienti
    IaaS è che la maggior parte dei fornitori PaaS fornisce una raccolta
    di servizi Cloud che offrono funzionalità diverse. Tali ambienti
    sono più adatti ad un pubblico di sviluppatori.

3. *IaaS (Infrastructure as a Service)*: precedentemente chiamata
    *Hardware as a Service*, fornisce potenza di elaborazione, storage e
    infrastruttura di rete (attraverso firewall e load balancing). È
    rivolta a tutti quei clienti che hanno bisogno di un ambiente per la
    propria applicazione fornendo servizi *on demand*, scalabili
    e flessibili. I fornitori di IaaS fanno un forte uso di tecnologie
    di virtualizzazione per la potenza di elaborazione. Tra i principali
    vendor del settore si evidenza Amazon. Il costo del servizio è
    calcolato in funzione alle ore di utilizzo, al trasferimento dei
    dati in/out per GB, alle richieste di I/O, al trasferimento dei dati
    in/out per GB di storage e altro ancora. Questo tipo di Cloud appare
    come un sinonimo di Grid Computing, ma con una caratteristica
    imprescindibile: le risorse sono utilizzate su richiesta al momento
    in cui un cliente ne ha bisogno, non vengono assegnate a prescindere
    dal loro utilizzo effettivo.


Il nostro obiettivo è di riuscire a comprendere le prospettive da cui
analizzare il Cloud poiché, dai modelli sopra esposti, è evidente che si
mostri adattabile a contesti estremamente diversificati tra loro: le
grandi aziende, le piccole imprese, i programmatori e gli utenti che già
oggi, a volte inconsapevolmente, fanno uso di tale tecnologia. Negli
ultimi anni si è assistito ad un cambiamento radicale dell’industria IT
sia nell’hardware che nel software, che consente a molti ricercatori di
considerare oggi il Cloud la risposta migliore alle proprie esigenze.
Non bisogna credere però che il Cloud abbia l’appoggio e l’adesione di
tutti.

Molti potrebbero avere la percezione che in realtà il Cloud non proponga
concetti molto innovativi. Outsourcing, affidabilità e continuità dei
servizi sono delle problematiche affrontate da sempre dalle aziende che
devono garantire ai propri clienti dei buoni servizi e a costi
ragionevoli. A tal proposito si riporta la testimonianza di Larry Elison
(CEO di Oracle):

*«The interesting thing about Cloud Computing is that we’ve redefined
Cloud Computing to include everything that we already do. . . . I don’t
understand what we would do differently in the light of Cloud Computing
other than change the wording of some of our ads».*

La preoccupazione maggiore di Elison e di molti altri suoi colleghi è
legata alla sensazione che il Cloud rientri in un disegno di business di
alcuni colossi aziendali che, se oggi sembrano voler offrire a tutti una
soluzione perfetta ai loro problemi (risorse *on demand* e senza limiti,
servizi economici e in molti casi gratuiti) nel lungo periodo
[possano](http://www.theinquirer.net/gb/inquirer/news/2008/09/30/stallman-warns-against-cloud)
invece rivelarsi oltremodo costosi. In una sua dichiarazione, Richard
Stallmann (fondatore della Free Software Foundation) afferma:

*«Il Cloud, una stupidaggine. Anzi, peggio di una stupidaggine: una
campagna marketing. Si tratta solo dell'ennesimo tentativo delle
corporation di ingabbiare gli utenti. Un tentativo da stroncare sul
nascere. Qualcuno dice che è inevitabile e quando sentite qualcuno dire
così, è molto probabile che si tratti di una strategia d'affari per
renderlo vero. Una ragione per non usare le web application è la perdita
del controllo. È un male proprio come usare programmi proprietari. Fate
il vostro lavoro su un vostro computer con un programma che rispetti le
vostre libertà: usando un programma proprietario sul server di qualcun
altro si è senza difese. Vi state mettendo nelle mani di chiunque abbia
sviluppato quel software».*

Considerando che nessuno può avere il potere di prevedere il futuro, al
momento il Cloud appare a tutti come la soluzione migliore alle esigenze
del mercato, al punto che anche quelle aziende che non hanno necessità
di migrare al Cloud sembrano volersi uniformare con il nuovo paradigma.
Sono d’altronde innegabili le potenzialità di questi servizi e
soprattutto i vantaggi che le piccole e grandi aziende possano trarne.
Abbiamo sottolineato più volte come il Cloud Computing abbia un impatto
su un vasto campo di utenza, si passa dalle grandi aziende, agli utenti
usuali e ai grandi gruppi di ricerca, ovviamente ciascun utente trae
diversi benefici in funzione delle proprie esigenze, motivo per cui la
nostra trattazione si focalizzerà inizialmente su ciascuna di esse. Ciò
che accumuna le grandi aziende ai piccoli programmatori è l’esigenza di
ridurre al massimo i propri costi ed è sicuramente il risparmio
economico uno dei motivi principali che spinge alla migrazione sul
Cloud.

Il Cloud consente ai suoi utenti di ridurre le spese hardware in
particolar modo se si pensa che, quando un’azienda fa un investimento,
sovradimensiona le risorse di cui necessita per evitare di trovarsi in
una situazione di saturazione delle risorse nei confronti dei propri
clienti. È proprio tale sovradimensionamento a provocare la crisi di
molte aziende che ovviamente, all’atto dell’investimento, possono
prevedere la domanda e il successo del loro business, il cui reale
impatto però non è ancora noto con certezza. Il Cloud è la soluzione a
questo problema, nessuno deve comprare le proprie risorse in funzione
delle previsioni del successo del proprio business. Il punto chiave del
Cloud è per l’appunto l’elasticità delle risorse, la possibilità di
richiederle in funzione della loro reale necessità, l’illusione di poter
avere un numero illimitato di risorse *on demand* e di pagare in
funzione del loro effettivo utilizzo. È un vantaggio dopo l’altro che da
un lato fa risparmiare una quantità ingente di denaro e dall’altro
consente a molte più aziende e a molti più utenti di poter essere
competitivi sul mercato e di poter aumentare il proprio fatturato.

Il Cloud Computing spazia in svariati rami applicativi da cui derivano
anche i diversi campi di utenza cui è rivolto. Va sottolineato che tutto
questo scenario deriva da un concetto molto più vasto conosciuto sotto
il nome di Web 2.0. Condivisione, collaborazione tra gli utenti
attraverso il web è alla base di questo nuovo paradigma, la necessità di
fare di Internet il maggiore spazio di ritrovo dei propri servizi e del
proprio business spinge tutt’oggi molte aziende a modificare
completamente il modo di lavorare. Basti pensare come il Web e il suo
sviluppo abbiano dato ai propri utenti nel corso di qualche anno cosi
tante opportunità che oggi i possibili fornitori non sono più le grandi
imprese che tutti conosciamo ma anche l’utente privato che con la sua
esperienza propone all’utenza di Internet i propri servizi. Siamo
nell’era delle applicazioni real-time, nelle quali la manipolazione di
grandi quantitativi di dati provenienti da campi applicativi diversi,
costringe le aziende a migrare sul Cloud per avere prestazioni elevate e
per poter far fronte alla flessibilità delle risorse disponibili.
L’utilizzo massiccio di Internet rende il web non solo il luogo migliore
in cui le aziende possono erogare i propri servizi, ma il modo migliore
attraverso cui recuperare le informazioni e le esigenze della loro
clientela.

    **Nota: **
    Un esempio è il servizio lanciato da qualche anno da Google:
    Google Analytics. Esso permette di tracciare, monitorare e misurare
    con grande accuratezza le statistiche web relative al traffico, alle
    conversioni, al ROI e alle pagine viste all'interno del proprio
    sito: informazioni utilissime per il business delle aziende

## Riferimenti

Barelli, L. (2009, Febbraio 27). Virtualizzazione e cloud, coppia perfetta. Tratto da Lineaedp: <http://www.lineaedp.it/01NET/HP/0,1254,1_ART_96633,00.html?lw=10001>

Candiello, A. (2004, Maggio). Grid Computing . Sistemi e Impresa, p.
118-122.

Farber, D. (2008). Oracle's Ellison nails cloud computing. Wall Street
Journal .

Ferrazza, F. (2005, Aprile 21). CAVIE STOP, C’E’ IL PC. L’Espresso.

Johnson, B. (2008). Cloud computing is a trap, warns GNU founder Richard
Stallman. Tratto da The Guardian:
<http://www.guardian.co.uk/technology/2008/sep/29/cloud.computing.richard.stallman>

Maruccia, A. (2009, Marzo 31). Il manifesto segreto del Cloud Computing.
Tratto da Punto Informatico:
<http://punto-informatico.it/2589549/PI/News/manifesto-segreto-del-cloud-computing.aspx>

Migliardi, M. (2004, Giugno). Grid Computing: Da dove viene e che cosa
manca perchè diventi una realtà?

Pijanowski, K. (2009, Maggio 31). Understanding Public Clouds: IaaS,
PaaS, & SaaS. Tratto da Keithpij.com:
<http://www.keithpij.com/Home/tabid/36/EntryID/27/Default.aspx>

Romagnolo, S. (2007, Gennaio 19). Grid computing: un prezioso alleato
informatico per la ricerca. Torino, Torino, Toscana.

#### Di [Roberto Freato](https://mvp.support.microsoft.com/profile/Roberto) – Microsoft MVP


